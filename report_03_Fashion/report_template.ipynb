{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report03 - 服装分类\n",
    "\n",
    "* 姓名 李晨\n",
    "* 学号 2018202069\n",
    "\n",
    "\n",
    "## 任务简介\n",
    "\n",
    "1. 任务类型   \n",
    "多分类问题\n",
    "2. 任务背景   \n",
    "FashionMNIST 是一个替代 MNIST 手写数字集的图像数据集。 它是由 Zalando（一家德国的时尚科技公司）旗下的研究部门提供。其涵盖了来自 10 种类别的共 7 万个不同商品的正面图片。\n",
    "\n",
    "3. 数据格式\n",
    "FashionMNIST 的大小、格式和训练集/测试集划分与原始的 MNIST 完全一致。60000/10000 的训练测试数据划分，28x28 的灰度图片。\n",
    "每个示例的高度为28个像素，宽度为28个像素，总共为784个像素。 每个像素具有与其相关联的单个像素值，指示该像素的亮度或暗度，较高的数字意味着较暗。 该像素值是0到255之间的整数。\n",
    "\n",
    "|T-short/top| Trouser|Pullover|Dress|Coat|Sandal|Shirt|Sneaker|Bag|Ankle boot|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|0|1|2|3|4|5|6|7|8|9|\n",
    "\n",
    "\n",
    "| / | Images_shape | Labels_shape | \n",
    "|:-:|:-:|:-:|\n",
    "|train data|(10000, 784)|(10000,)|\n",
    "|test data |(60000, 784)|(60000,)|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train data] : Images_shape = (10000, 784), Labels_shape = (10000,)\n",
      "[test  data] : Images_shape = (60000, 784), Labels_shape = (60000,)\n"
     ]
    }
   ],
   "source": [
    "import os.path as path\n",
    "import numpy as np\n",
    "\n",
    "# 读取训练数据与展示\n",
    "def loadData(f):\n",
    "    f = path.join('fashion-mnist', f + '.npy')\n",
    "    matrix = np.load(f)\n",
    "    return matrix\n",
    "\n",
    "trainImages, trainLabels = loadData('train-images'), loadData('train-labels')\n",
    "testImages, testLabels = loadData('t10k-images'), loadData('t10k-labels')\n",
    "\n",
    "print(f'[train data] : Images_shape = {trainImages.shape}, Labels_shape = {trainLabels.shape}')\n",
    "print(f'[test  data] : Images_shape = {testImages.shape}, Labels_shape = {testLabels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解决途径\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "服装分类是一个多分类问题，搭建`全连接网络模型`实现分类和将训练数据处理后使用`卷积神经网络`都可以实现这样的分类功能，首先我们搭建全联接网络。\n",
    "### 全连接网络（FCN）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 数据处理   \n",
    "将读入的数据转化成torch使用的tensor类型；同时对测试数据进行分批，每一batch的测试数据与训练数据大小相同，防止出现内存溢出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = torch.from_numpy(trainImages).float()\n",
    "trainLabels = torch.from_numpy(trainLabels).long()\n",
    "\n",
    "testEpoches = []\n",
    "epochLen, dataLen = trainImages.shape[0], testImages.shape[0]\n",
    "for i in range(0, dataLen, epochLen):\n",
    "    start, end = i, min(i + epochLen, dataLen)\n",
    "    testEpoches.append((\n",
    "        torch.from_numpy(testImages[start:end]).float(),\n",
    "        testLabels[start:end]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 定义全连接网络模块(FCN)   \n",
    "这个简单的全连接网络需要传递进去的参数有：输入的维度，每个隐藏层的维度，以及输出层的维度。在这个模型中，我们使用`nn.ELU()`激活函数来增加网络的非线性，使用`nn.Sequential()`来将网络的层组合在一起作为`self.layer`；网络的最后一层`输出层`不能添加激活函数；使用`nn.BatchNormld()`函数来加快收敛的速度，同样使用`nn.Sequential()`来将`nn.BatchNormld()`组合在网络层中。批标准化一般放在全连接层的后面，非线性层激活函数的前面。    \n",
    "`forward()`函数是前向传播函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myFCNModule(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        i, self.layer = 1, nn.Sequential()\n",
    "        for h_dim in hidden_dim:\n",
    "            self.layer.add_module('layer_{}'.format(i),\n",
    "                                  # 线性模块\n",
    "                                  nn.Sequential(nn.Linear(in_dim, h_dim), \n",
    "                                  # 批归一化\n",
    "                                  nn.BatchNorm1d(h_dim),\n",
    "                                  # ELU增加非线性\n",
    "                                  nn.ELU(True)))\n",
    "            i, in_dim = i + 1, h_dim\n",
    "        self.layer.add_module('layer_{}'.format(i), nn.Sequential(nn.Linear(in_dim, out_dim)))\n",
    "        self.layerNum = i\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 导入网络并进行待以损失函数及优化方法  \n",
    "因为输入的图片大小为`28*28`，所以输入维度是`28*28`，然后定义两个隐藏层分别是512和256，输出维度必须是10，因为这是一个10分类问题。  \n",
    "损失函数定义为最常见的损失交叉墒函数，使用随机梯度下降来优化损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数（Hyperparameters）\n",
    "learning_rate = 1e-2\n",
    "\n",
    "myFCN = myFCNModule(784, [512, 256], 10)\n",
    "if torch.cuda.is_available():\n",
    "    myFCN = myFCN.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(myFCN.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 定义训练过程和测试过程\n",
    "定义训练参数`numEpoches, printStep = 2000, 100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch  100]: acc = 0.24\n",
      "[epoch  200]: acc = 0.7611\n",
      "[epoch  300]: acc = 0.7963\n",
      "[epoch  400]: acc = 0.8109\n",
      "[epoch  500]: acc = 0.819\n",
      "[epoch  600]: acc = 0.8245\n",
      "[epoch  700]: acc = 0.8292\n",
      "[epoch  800]: acc = 0.8343\n",
      "[epoch  900]: acc = 0.8387\n",
      "[epoch 1000]: acc = 0.8412\n",
      "[epoch 1100]: acc = 0.844\n",
      "[epoch 1200]: acc = 0.846\n",
      "[epoch 1300]: acc = 0.8477\n",
      "[epoch 1400]: acc = 0.8493\n",
      "[epoch 1500]: acc = 0.8513\n",
      "[epoch 1600]: acc = 0.8539\n",
      "[epoch 1700]: acc = 0.8543\n",
      "[epoch 1800]: acc = 0.8556\n",
      "[epoch 1900]: acc = 0.8415\n",
      "[epoch 2000]: acc = 0.8386\n"
     ]
    }
   ],
   "source": [
    "def train(trainImages, trainLabels):\n",
    "    myFCN.train()\n",
    "    inputs, labels = Variable(trainImages), Variable(trainLabels)\n",
    "    if torch.cuda.is_available():\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "    outputs = myFCN(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "def test(test_inputs, outVector=False):\n",
    "    myFCN.eval()\n",
    "    inputs = Variable(test_inputs)\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = inputs.cuda()\n",
    "    outputs = myFCN(inputs)\n",
    "    if outVector:\n",
    "        return outputs\n",
    "    _, predict = torch.max(outputs.data, 1)\n",
    "    return predict\n",
    "\n",
    "numEpoches, printStep = 2000, 100\n",
    "\n",
    "# 保存过程中的精确度\n",
    "steps, accs = [], []\n",
    "\n",
    "for epoch in range(numEpoches):\n",
    "    train(trainImages, trainLabels)\n",
    "    if epoch % printStep == 0:\n",
    "        numCorrect, allNum = 0, 0\n",
    "        for inputs, labels in testEpoches:\n",
    "            predict = test(inputs)\n",
    "            predict = predict.cpu().numpy()\n",
    "            numCorrect = (predict == labels).sum()\n",
    "            allNum += labels.shape[0]\n",
    "        acc = numCorrect / labels.shape[0]\n",
    "        steps.append(epoch + printStep)\n",
    "        accs.append(acc)\n",
    "        print(f'[epoch {epoch + printStep:>4}]: acc = {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 测试过程可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14c54e320>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(steps, accs, label='accurency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'FCN prediction heatmap')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatList = [[np.zeros((10,)), 0] for _ in range(10)]\n",
    "for inputs, targets in testEpoches:\n",
    "    predicts = test(inputs, True)\n",
    "    predicts = predicts.cpu().detach().numpy()\n",
    "    for predict, target in zip(predicts, targets):\n",
    "        heatList[target][0] += predict\n",
    "        heatList[target][1] += 1\n",
    "\n",
    "for i, heat in enumerate(heatList):\n",
    "    heatList[i][0] = heat[0] / heat[1]\n",
    "heatMap = np.concatenate([heat[0][np.newaxis, :] for heat in heatList])\n",
    "    \n",
    "plt.imshow(heatMap, cmap='viridis', interpolation='nearest')\n",
    "plt.title(f'FCN prediction heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "这次报告由于时间问题我没有在写爬虫程序爬取图片进行测试，在所给的测试集上达到了85%的准确率。\n",
    "这次报告主要是使用PyTorch学习框架搭建了简单的FCN全连接网络，主要过程主要是网络模型的搭建。分类的准确率达到了80%以上。\n",
    "对于图片的多分类任务，有很多可以使用的现成的网络模型，比如ResNet18，VGGNet等等，这些卷积神经网络由于卷积层的作用，在图片分类的效果要比简单的全连接网络好一些。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "main_language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
